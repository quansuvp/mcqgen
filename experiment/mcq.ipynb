{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a918220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a84f5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4c65bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e8093186",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=256,\n",
    "    timeout=None,\n",
    "    max_retries=1,\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    # organization=\"...\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7955d7a8",
   "metadata": {},
   "source": [
    "## Note for new chain usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "c49ee592",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"subject\":\"A\",\n",
    "    \"quiz\":{\n",
    "        \"1\": {\n",
    "            \"mcq\": \"multiple choice question\",\n",
    "            \"options\": {\n",
    "                \"A\": \"option A\",\n",
    "                \"B\": \"option B\",\n",
    "                \"C\": \"option C\",\n",
    "                \"D\": \"option D\"\n",
    "            },\n",
    "            \"answer\": \"A\"\n",
    "        },\n",
    "        \"2\": {\n",
    "            \"mcq\": \"multiple choice question\",\n",
    "            \"options\": {\n",
    "                \"A\": \"option A\",\n",
    "                \"B\": \"option B\",\n",
    "                \"C\": \"option C\",\n",
    "                \"D\": \"option D\"\n",
    "            },\n",
    "            \"answer\": \"B\"\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "eaf20e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "Text:{text}\n",
    "You are a quiz generation AI. Your task is to generate a quiz of {number} choice questions for {subject} students in {tone} tone\\\n",
    "based on the provided text. \\\n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well. \\\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "58273ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = ChatPromptTemplate.from_template(TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "b5f5f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a multiple choice quiz for {subject} students.\\\n",
    "Your task is to analyze the quiz and provide feedback on its grammatical correctness, clarity, and overall complexity.Only use at max 50 words for complexity.\\\n",
    "Please ensure that your feedback is constructive and aimed at helping the quiz creator improve their work.\\\n",
    "Update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities.\\\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f880ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_review_prompt= ChatPromptTemplate.from_template(TEMPLATE2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999eda3",
   "metadata": {},
   "source": [
    "### Case 1: Leverage RunnablePassthrough\n",
    "\n",
    "- Sequential Chain is similar to Sequential Model in Keras that it will take the output of previous chain as input of the next chain\n",
    "\n",
    "- Input of Chain is in form of dictionary ex:\n",
    "    ```\n",
    "        input_params = {\n",
    "            \"text\": \"What is the capital of France\",\n",
    "            \"subject\": \"Geography\", \n",
    "            \"tone\": \"Formal\",\n",
    "            \"number\": 1,\n",
    "            \"response_json\": RESPONSE_JSON\n",
    "        }\n",
    "    ```\n",
    "\n",
    "- ```JsonOutputParser``` will cast a JSON object to dictionary in Python so it is a need between 2 chains if the previous chain output JSON object. I consider it as a bonding\n",
    "\n",
    "- ```RunnablePassthrough``` is used to customize the input to the chain like adding key ```quiz_result``` and ```original_input``` to the output of first chain and then use ```RunnableLambda``` and function ```add_quiz_to_params``` to create a suittable input that required by the next chain.\n",
    "\n",
    "- ```json.dumps()``` to serialize python dictionary to JSON-formatted string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5bbc0350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quiz_to_params(result):\n",
    "    # This function adds the quiz result back to the original parameters\n",
    "    original_input = result[\"original_input\"]\n",
    "    quiz_data = result[\"quiz_result\"]\n",
    "    print(quiz_data)\n",
    "    return {\n",
    "        \"quiz\": json.dumps(quiz_data, indent=2),\n",
    "        \"subject\": original_input[\"subject\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "089371ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser()\n",
    "generate_review_chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            quiz_result=(\n",
    "                quiz_generation_prompt \n",
    "                | llm \n",
    "                | parser\n",
    "            )\n",
    "        ).assign(\n",
    "            original_input=lambda x: x\n",
    "        )\n",
    "        | RunnableLambda(add_quiz_to_params)\n",
    "        | quiz_review_prompt\n",
    "        | llm\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728a7de",
   "metadata": {},
   "source": [
    "### Case 2: Raw usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827524c",
   "metadata": {},
   "source": [
    "- If we already required the LLMs to format the output of the first chain following the requirements of the input of the second chain we can use it directly\n",
    "\n",
    "- However ```Case 1 ``` offer us more flexible implementation as this case do not allow us to view the output of intermediate chain but last chain. While ```Case 1 ``` with the RunnableLambda we can do that by simply adding ```print``` to the custom function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "20bd9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputParser()\n",
    "generate_review_chain = (\n",
    "    quiz_generation_prompt \n",
    "    | llm \n",
    "    | parser  # Parse JSON string to dictionary\n",
    "    | RunnablePassthrough.assign(\n",
    "            quiz_result=(\n",
    "                quiz_review_prompt\n",
    "                | llm\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f65d462",
   "metadata": {},
   "source": [
    "### Invoke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "400db1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_params = {\n",
    "    \"text\": \"What is the capital of France\",\n",
    "    \"subject\": \"Geography\", \n",
    "    \"tone\": \"Formal\",\n",
    "    \"number\": 1,\n",
    "    \"response_json\": RESPONSE_JSON\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ee035804",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = generate_review_chain.invoke(input_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "4f7dec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['subject', 'quiz', 'quiz_result'])\n",
      "{'1': {'mcq': 'What is the capital of France?', 'options': {'A': 'Paris', 'B': 'London', 'C': 'Berlin', 'D': 'Rome'}}}\n",
      "Feedback: \n",
      "The quiz question is clear and simple, suitable for Geography students. However, it could be improved by adding more diverse and challenging questions to test the students' knowledge further. Consider incorporating questions about physical geography or world cultures to enhance the quiz.\n"
     ]
    }
   ],
   "source": [
    "print(result.keys())\n",
    "print(result['quiz'])\n",
    "print(result['quiz_result'].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24f811a",
   "metadata": {},
   "source": [
    "## Callbacks to track TOKEN usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d0227d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users/khang/Desktop/mcqgen/experiment/data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0d7b753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.[1] Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.[2]\n",
      "\n",
      "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\n",
      "\n",
      "Statistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) via unsupervised learning.[4][5]\n",
      "\n",
      "From a theoretical viewpoint, probably approximately correct learning provides a framework for describing machine learning.\n"
     ]
    }
   ],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    TEXT = file.read()\n",
    "print(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "16548d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 814\n",
      "\tPrompt Tokens: 581\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 233\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0001513\n"
     ]
    }
   ],
   "source": [
    "SUBJECT = 'machine learning'\n",
    "TONE = 'Formal'\n",
    "NUMBER = 1\n",
    "\n",
    "input_params = {\n",
    "    \"text\": TEXT,\n",
    "    \"subject\": SUBJECT, \n",
    "    \"tone\": TONE,\n",
    "    \"number\": NUMBER,\n",
    "    \"response_json\": RESPONSE_JSON\n",
    "}\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = generate_review_chain.invoke(input_params)\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6fecd97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"1\": {\n",
      "        \"mcq\": \"Which of the following best describes the primary goal of machine learning?\",\n",
      "        \"options\": {\n",
      "            \"A\": \"To develop algorithms that can learn from data and generalise to unseen data without explicit instructions\",\n",
      "            \"B\": \"To manually program all possible tasks for a computer to perform\",\n",
      "            \"C\": \"To replace all human decision-making processes with fixed rules\",\n",
      "            \"D\": \"To analyze only structured data without making predictions\"\n",
      "        },\n",
      "        \"answer\": \"A\"\n",
      "    }\n",
      "}\n",
      "The question is clear and grammatically correct, but options could be simplified for student clarity. Option D is slightly confusing; clarify that it refers to limited data types. \n",
      "\n",
      "Revised question:\n",
      "**Which best describes the main goal of machine learning?**  \n",
      "A) To create algorithms that learn from data and make predictions on new, unseen data.  \n",
      "B) To manually program every task a computer should perform.  \n",
      "C) To replace all human decisions with fixed rules.  \n",
      "D) To analyze only structured data without making predictions.\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(result['quiz'], indent=4))\n",
    "print(result['quiz_result'].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
